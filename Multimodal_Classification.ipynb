{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Multimodal_Classification.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYcgKbqJZpXL"
      },
      "source": [
        "# Multimodal Classification Kaggle Competition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR1w569OZw7o"
      },
      "source": [
        "Thomas Nigoghossian "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS5XDDvGZpXR"
      },
      "source": [
        "This multimodal classification problem is a supervised classification problem: from labeled images and sound files, a model capable of classifying new inputs must be established.\n",
        "\n",
        "This notebook was made during an ENSTA competition on Kaggle and it ranked 1st with an accuracy of 0.99942.\n",
        "\n",
        "In this notebook, I explain my approach to achieve this result and I propose some analysis of the result (including the quality of the dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksRp6dJqZpXS"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-11-22T18:35:45.736456Z",
          "iopub.execute_input": "2021-11-22T18:35:45.736795Z",
          "iopub.status.idle": "2021-11-22T18:35:46.830125Z",
          "shell.execute_reply.started": "2021-11-22T18:35:45.736720Z",
          "shell.execute_reply": "2021-11-22T18:35:46.829344Z"
        },
        "trusted": true,
        "id": "XCVRqndYZpXT"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "datadir = '/kaggle/input/multimodal-classification-2021-mi203'\n",
        "\n",
        "import os\n",
        "'''\n",
        "for dirname, _, filenames in os.walk(datadir):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "'''\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "\n",
        "\n",
        "traindata = pd.read_csv(os.path.join(datadir,'data/data_train.csv'), delimiter=',', nrows = None)\n",
        "data = np.array(traindata)\n",
        "\n",
        "y_train = data[:,-1].astype('int32')\n",
        "\n",
        "audio_train = data[:, 1:-1]\n",
        "\n",
        "trainimg_list = traindata['IMAGE']\n",
        "\n",
        "testdata = pd.read_csv(os.path.join(datadir,'data/data_test_novt.csv'), delimiter=',', nrows = None)\n",
        "data = np.array(testdata)\n",
        "\n",
        "audio_test = np.array(data[:, 1:], dtype='float64')\n",
        "\n",
        "testimg_list = testdata['IMAGE']\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T18:35:46.832350Z",
          "iopub.execute_input": "2021-11-22T18:35:46.832904Z",
          "iopub.status.idle": "2021-11-22T18:35:47.818893Z",
          "shell.execute_reply.started": "2021-11-22T18:35:46.832810Z",
          "shell.execute_reply": "2021-11-22T18:35:47.818097Z"
        },
        "trusted": true,
        "id": "9gVMJKubZpXW"
      },
      "source": [
        "#====================================================================\n",
        "# Pour séparer les données en apprentissage et test\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(audio_train)\n",
        "\n",
        "audio_train_scaled = scaler.transform(audio_train)\n",
        "\n",
        "Xn, Xv, yn, yv = train_test_split(audio_train_scaled, y_train,\n",
        "                                                    random_state=42,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WFw1mhkZpXY"
      },
      "source": [
        "# I. Sound approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mh4BUx6ZpXZ"
      },
      "source": [
        "**In this first part, we focus only on the audio data**.\n",
        "i.e. we have for each element of the database a hundred of coefficients called Mel-Frequency Cepstral Coefficients (MFCC) which are very used for feature extraction in audio files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR4pzYIsZpXa"
      },
      "source": [
        "# 1.  Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U440ThL0ZpXb"
      },
      "source": [
        "We have a classification problem. From digital data, we have to give a label to a sound file.\n",
        "Our first approach is to build a simplistic model in order to measure the model and to check if it is necessary to\n",
        "complex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJJYPK_MZpXb"
      },
      "source": [
        "For this we chose to start with decision trees.\n",
        "We could have tried a k-nearest neighbor model. However, our database contains too many features to hope for a good result. We would certainly have been confronted with the curse of high dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T18:35:47.820428Z",
          "iopub.execute_input": "2021-11-22T18:35:47.820756Z",
          "iopub.status.idle": "2021-11-22T18:35:49.410358Z",
          "shell.execute_reply.started": "2021-11-22T18:35:47.820721Z",
          "shell.execute_reply": "2021-11-22T18:35:49.409507Z"
        },
        "trusted": true,
        "id": "nyiXJqTuZpXc"
      },
      "source": [
        "from sklearn import tree\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"gini\",max_depth=30,min_samples_split=50, splitter=\"best\")\n",
        "clf = clf.fit(Xn,yn )\n",
        "\n",
        "preds = clf.predict(Xv)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T18:35:49.411539Z",
          "iopub.execute_input": "2021-11-22T18:35:49.411873Z",
          "iopub.status.idle": "2021-11-22T18:35:49.419914Z",
          "shell.execute_reply.started": "2021-11-22T18:35:49.411837Z",
          "shell.execute_reply": "2021-11-22T18:35:49.419038Z"
        },
        "trusted": true,
        "id": "eEqPVjMFZpXd"
      },
      "source": [
        "import sklearn.metrics as perf\n",
        "\n",
        "#affichage du score\n",
        "def show_result(preds):\n",
        "    oa = perf.accuracy_score(yv, preds)\n",
        "    bas = perf.balanced_accuracy_score(yv, preds) #moyenne des scores dans chaque classes\n",
        "    cm = perf.confusion_matrix(yv, preds)\n",
        "    print(\"Accuracy_score : \",oa,\"Balanced_accuracy_score : \",bas)\n",
        "    print(\"Matrice de confusion\")\n",
        "    print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T18:35:49.424585Z",
          "iopub.execute_input": "2021-11-22T18:35:49.424842Z",
          "iopub.status.idle": "2021-11-22T18:35:49.444021Z",
          "shell.execute_reply.started": "2021-11-22T18:35:49.424812Z",
          "shell.execute_reply": "2021-11-22T18:35:49.443358Z"
        },
        "trusted": true,
        "id": "PcDjxPpaZpXe"
      },
      "source": [
        "show_result(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZohTk1sZpXf"
      },
      "source": [
        "We define the tree_optimizer function. It allows us to determine the parameters that will give the best results for our decision tree. The parameters in question are: max_depth and min_samples_split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T18:35:49.447803Z",
          "iopub.execute_input": "2021-11-22T18:35:49.448078Z",
          "iopub.status.idle": "2021-11-22T18:35:49.456466Z",
          "shell.execute_reply.started": "2021-11-22T18:35:49.448050Z",
          "shell.execute_reply": "2021-11-22T18:35:49.455462Z"
        },
        "trusted": true,
        "id": "6K8LfhVgZpXh"
      },
      "source": [
        "def tree_optimizer():\n",
        "    res = 0\n",
        "    best_max_depth = 2\n",
        "    best_min_samples_split = 2\n",
        "    for i in range(2,50):\n",
        "        for j in range(2,50):\n",
        "            clf = tree.DecisionTreeClassifier(criterion=\"gini\",max_depth=i,min_samples_split=j, splitter=\"best\")\n",
        "            clf = clf.fit(trainx,trainy )\n",
        "            preds = clf.predict(testx)\n",
        "            acc = perf.balanced_accuracy_score( testy, preds )\n",
        "            if (acc > res):\n",
        "                res = acc\n",
        "                best_max_depth = i\n",
        "                best_min_samples_split = j\n",
        "                print(acc)\n",
        "    return i,j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOw6DSGkZpXi"
      },
      "source": [
        "Result\n",
        "==\n",
        "Thanks to this function, we quickly observe a level in the results.\n",
        "Indeed, the maximum score obtained with a tree is: 0.6935632245695139  \n",
        "Knowing that there are 9 different classes, a random model would have a result of 0.11. Thus a decision tree allows to obtain satisfactory results in a simple and fast way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX7n8AimZpXj"
      },
      "source": [
        "# 2. Random Forest / Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF84CJjtZpXj"
      },
      "source": [
        "Then comes the problem of how to optimize this first model. For this we will perform bagging with decision trees, i.e. we will develop a random forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T18:35:49.458493Z",
          "iopub.execute_input": "2021-11-22T18:35:49.458755Z",
          "iopub.status.idle": "2021-11-22T18:36:12.521224Z",
          "shell.execute_reply.started": "2021-11-22T18:35:49.458732Z",
          "shell.execute_reply": "2021-11-22T18:36:12.520358Z"
        },
        "trusted": true,
        "id": "nZGW4d0BZpXk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def learn_forest(XTrain, yTrain, nb_trees, depth=15):\n",
        "    forest = []\n",
        "    singleperf=[]\n",
        "\n",
        "    for ss in range(nb_trees):\n",
        "        # bagging for subset\n",
        "        X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(\n",
        "            XTrain, yTrain, test_size=0.2 )\n",
        "\n",
        "        # single tree training\n",
        "        clf = tree.DecisionTreeClassifier(criterion=\"gini\",max_depth=30,min_samples_split=50, splitter=\"best\")\n",
        "        clf = clf.fit( X_train_sub, y_train_sub )\n",
        "\n",
        "        # grow the forest\n",
        "        forest.append( clf )\n",
        "\n",
        "        # single tree evaluation\n",
        "        curr_train_pred=clf.predict(X_train_sub)\n",
        "        curr_test_pred=clf.predict(X_test_sub)\n",
        "        singleperf.append([perf.balanced_accuracy_score( y_train_sub, curr_train_pred ), perf.balanced_accuracy_score( y_test_sub,curr_test_pred)])\n",
        "\n",
        "    return forest,singleperf\n",
        "\n",
        "#Renvoi un array contenant les prédictions de notre random forest\n",
        "def most_frequent(preds):\n",
        "    res = np.empty((preds.shape[0],1))\n",
        "    for i in range(preds.shape[0]):\n",
        "        occurence_count = Counter(preds[i].tolist())\n",
        "        res[i] = occurence_count.most_common(1)[0][0]\n",
        "    return res\n",
        "\n",
        "#transforme la matrice où chaque ligne correspond aux predictions d'un arbre en une matrice où chaque ligne correspond aux prédictions de tous les arbres sur le même cas\n",
        "def array_transform(preds):\n",
        "    final_array = np.empty((preds.shape[1],preds.shape[0]))\n",
        "    for i in range(preds.shape[1]):\n",
        "        for j in range(preds.shape[0]):\n",
        "            final_array[i][j] = preds[j][i]\n",
        "    return final_array\n",
        "\n",
        "def predict_forest(forest, XTest, yTest = None):\n",
        "  \n",
        "    singleperf=[]\n",
        "    all_preds=[]\n",
        "    nb_trees = len(forest)\n",
        "    for ss in forest:# nb_trees\n",
        "        test_pred=ss.predict(XTest)\n",
        "        all_preds.append(test_pred)\n",
        "\n",
        "        if (yTest is not None):\n",
        "            singleperf.append(perf.balanced_accuracy_score( yTest, test_pred ))\n",
        "\n",
        "    all_preds=np.array(all_preds)\n",
        "    #print(all_preds)\n",
        "\n",
        "  # Vote\n",
        "    final_preds = array_transform(all_preds)\n",
        "    final_pred = most_frequent(final_preds)\n",
        "\n",
        "    if (yTest is not None):\n",
        "        return final_pred,singleperf\n",
        "    else:\n",
        "        return final_pred\n",
        "\n",
        "\n",
        "F,singleperf = learn_forest(Xn,yn, 20, depth=15)\n",
        "pred = predict_forest(F, Xv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T18:36:12.522646Z",
          "iopub.execute_input": "2021-11-22T18:36:12.522989Z",
          "iopub.status.idle": "2021-11-22T18:36:12.559109Z",
          "shell.execute_reply.started": "2021-11-22T18:36:12.522955Z",
          "shell.execute_reply": "2021-11-22T18:36:12.558134Z"
        },
        "trusted": true,
        "id": "U6-bRv_5ZpXl"
      },
      "source": [
        "show_result(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdwvUqeiZpXm"
      },
      "source": [
        "Result\n",
        "==\n",
        "Using a Random Forest, it is possible to obtain a score of about 79%!\n",
        "So we have improved the model by 10 points, but this is not enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fxO3hi_ZpXn"
      },
      "source": [
        "# 3. Boosting / XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TkSvQozZpXo"
      },
      "source": [
        "Finally, we will use boosting to try to improve the model. To do this, we will use the xgboost library, which allows us to implement a simple gradient boosting algorithm.\n",
        "\n",
        "https://xgboost.readthedocs.io/en/latest/index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T18:36:12.560831Z",
          "iopub.execute_input": "2021-11-22T18:36:12.561203Z",
          "iopub.status.idle": "2021-11-22T19:12:36.284414Z",
          "shell.execute_reply.started": "2021-11-22T18:36:12.561164Z",
          "shell.execute_reply": "2021-11-22T19:12:36.283635Z"
        },
        "trusted": true,
        "id": "X5YYtd9TZpXp"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "xgbc = XGBClassifier(booster='gbtree',max_depth=15,n_estimators=500,use_label_encoder=False,learning_rate=0.8)\n",
        "\n",
        "xgbc.fit(Xn, yn)\n",
        "scores = cross_val_score(xgbc, Xn, yn, cv=5)\n",
        "print(\"Mean cross-validation score: %.2f\" % scores.mean())\n",
        " \n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "kf_cv_scores = cross_val_score(xgbc, Xn, yn, cv=kfold )\n",
        "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:18:39.507404Z",
          "iopub.execute_input": "2021-11-22T19:18:39.507797Z",
          "iopub.status.idle": "2021-11-22T19:18:39.652090Z",
          "shell.execute_reply.started": "2021-11-22T19:18:39.507755Z",
          "shell.execute_reply": "2021-11-22T19:18:39.651133Z"
        },
        "trusted": true,
        "id": "yfcKSryFZpXq"
      },
      "source": [
        "ypred = xgbc.predict(Xv)\n",
        "\n",
        "show_result(ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:18:42.601891Z",
          "iopub.execute_input": "2021-11-22T19:18:42.602251Z",
          "iopub.status.idle": "2021-11-22T19:18:42.621140Z",
          "shell.execute_reply.started": "2021-11-22T19:18:42.602218Z",
          "shell.execute_reply": "2021-11-22T19:18:42.619938Z"
        },
        "trusted": true,
        "id": "_FbGF448ZpXq"
      },
      "source": [
        "xgbc.plot_importance(boost)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhEwM9VkZpXq"
      },
      "source": [
        "Result\n",
        "==\n",
        "After a (long) training, we obtain a score of 90%, which is an increase of 10 points compared to the previous method.  \n",
        "The disadvantage of this method is that it is very long. It is therefore difficult to find the best parameters to optimize the result.  \n",
        "The advantage of this method, in addition to the performance, is that it directly includes a cross validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l00HbnuZpXq"
      },
      "source": [
        "# 4. SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr2lNBkkZpXr"
      },
      "source": [
        "Finally, we will leave the trees aside and experiment with SVMs.  \n",
        "The use of SVMs seems to make sense since we have to find how to separate points in high dimension. We will see that the use of a non-linear kernel allows to obtain very good results.\n",
        "\n",
        "NB: This approach is provided by the teacher. Only the optimization of the parameters has been modified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQP8q3_4ZpXr"
      },
      "source": [
        "# SVM Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:18:53.482553Z",
          "iopub.execute_input": "2021-11-22T19:18:53.482880Z",
          "iopub.status.idle": "2021-11-22T19:18:55.197250Z",
          "shell.execute_reply.started": "2021-11-22T19:18:53.482848Z",
          "shell.execute_reply": "2021-11-22T19:18:55.196319Z"
        },
        "trusted": true,
        "id": "CcL2SdhHZpXr"
      },
      "source": [
        "#====================================================================\n",
        "#   Apprentissage (SVM)\n",
        "\n",
        "from sklearn import svm\n",
        "svc = svm.LinearSVC(max_iter=10000, tol=1e-4, verbose=True, dual=False)\n",
        "\n",
        "svc.fit(Xn, yn)\n",
        "\n",
        "score_train = svc.score(Xn, yn)\n",
        "score_test = svc.score(Xv, yv)\n",
        "\n",
        "print(\"Taux de reco = {:.2f}% / {:.2f}%\".format(score_train*100, score_test*100))\n",
        "\n",
        "# Prédiction\n",
        "y_pred = svc.predict(scaler.transform(audio_test))\n",
        "print(\"Taux de reco = {:.2f}% / {:.2f}%\".format(score_train*100, score_test*100))\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msOhCQ0VZpXr"
      },
      "source": [
        "# Noyau RBF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:18:56.507476Z",
          "iopub.execute_input": "2021-11-22T19:18:56.507792Z",
          "iopub.status.idle": "2021-11-22T19:19:12.839399Z",
          "shell.execute_reply.started": "2021-11-22T19:18:56.507761Z",
          "shell.execute_reply": "2021-11-22T19:19:12.838476Z"
        },
        "trusted": true,
        "id": "GwfQ7pEgZpXr"
      },
      "source": [
        "#====================================================================\n",
        "#   Apprentissage (SVM)\n",
        "\n",
        "from sklearn import svm\n",
        "svc = svm.SVC(kernel='rbf', max_iter=-1, verbose = True, C=10, gamma='auto')\n",
        "\n",
        "svc.fit(Xn, yn)\n",
        "\n",
        "score_train = svc.score(Xn, yn)\n",
        "score_test = svc.score(Xv, yv)\n",
        "\n",
        "print(\"Taux de reco = {:.2f}% / {:.2f}%\".format(score_train*100, score_test*100))\n",
        "\n",
        "# Prédiction\n",
        "\n",
        "y_pred = svc.predict(scaler.transform(audio_test))\n",
        "print(\"Taux de reco = {:.2f}% / {:.2f}%\".format(score_train*100, score_test*100))\n",
        "print(y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:24:18.373450Z",
          "iopub.execute_input": "2021-11-22T19:24:18.373807Z",
          "iopub.status.idle": "2021-11-22T19:24:20.718934Z",
          "shell.execute_reply.started": "2021-11-22T19:24:18.373775Z",
          "shell.execute_reply": "2021-11-22T19:24:20.718190Z"
        },
        "trusted": true,
        "id": "25M15PISZpXs"
      },
      "source": [
        "y_pred = svc.predict(Xv)\n",
        "show_result(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEAZOABAZpXx"
      },
      "source": [
        "Result\n",
        "==\n",
        "With an SVM we quickly get very good results. The best configuration is to use a RBF (Radial basis function) kernel.  \n",
        "However, we can see a difference between the score on the training base and the test base. The model is in overfitting. Indeed, we obtain almost 100% of success on the training base but \"only\" 93% on the test base.\n",
        "To avoid overlearning, we have to vary the parameters C and gamma which modify the size of the margin and the accepted classification errors.  \n",
        "Note that polynomial kernels also give good results (around 90%)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMw0wN9RZpXx"
      },
      "source": [
        "# II. Image Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GBS4SrLZpXy"
      },
      "source": [
        "In this part, we will try to develop a model using only the images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc17o-YiZpXy"
      },
      "source": [
        "# Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:24:20.722178Z",
          "iopub.execute_input": "2021-11-22T19:24:20.722432Z",
          "iopub.status.idle": "2021-11-22T19:24:21.286432Z",
          "shell.execute_reply.started": "2021-11-22T19:24:20.722406Z",
          "shell.execute_reply": "2021-11-22T19:24:21.285410Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "Pbf6LLY1ZpXy",
        "outputId": "50784f67-3e34-45de-ffd1-cb9e8747eb89"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "datadir = '/kaggle/input/multimodal-classification-2021-mi203/data'\n",
        "#datadir = 'data'\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "\n",
        "data_df = pd.read_csv(os.path.join(datadir,'data_train.csv'), delimiter=',', nrows = None)\n",
        "data = np.array(data_df)\n",
        "\n",
        "labels = data[:,-1].astype('int32')\n",
        "\n",
        "audio = data[:, 1:-1].astype('float32')\n",
        "\n",
        "img_list = data_df['IMAGE']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-57734d0245ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/multimodal-classification-2021-mi203/data/data_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:24:21.287993Z",
          "iopub.execute_input": "2021-11-22T19:24:21.288383Z",
          "iopub.status.idle": "2021-11-22T19:24:21.297818Z",
          "shell.execute_reply.started": "2021-11-22T19:24:21.288344Z",
          "shell.execute_reply": "2021-11-22T19:24:21.296735Z"
        },
        "trusted": true,
        "id": "tSRIi65cZpXy"
      },
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:24:21.299873Z",
          "iopub.execute_input": "2021-11-22T19:24:21.300607Z",
          "iopub.status.idle": "2021-11-22T19:24:21.509483Z",
          "shell.execute_reply.started": "2021-11-22T19:24:21.300563Z",
          "shell.execute_reply": "2021-11-22T19:24:21.508371Z"
        },
        "trusted": true,
        "id": "GXTJvPvKZpXy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# visu image\n",
        "idx = 0\n",
        "class_list = ['FOREST', 'CITY', 'BEACH', 'CLASSROOM', 'RIVER', 'JUNGLE', 'RESTAURANT', 'GROCERY-STORE', 'FOOTBALL-MATCH']\n",
        "img = Image.open(os.path.join(datadir, img_list.iloc[idx]))\n",
        "plt.imshow(np.asarray(img))\n",
        "print(class_list[labels[idx]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:24:21.512821Z",
          "iopub.execute_input": "2021-11-22T19:24:21.513220Z",
          "iopub.status.idle": "2021-11-22T19:24:21.652356Z",
          "shell.execute_reply.started": "2021-11-22T19:24:21.513188Z",
          "shell.execute_reply": "2021-11-22T19:24:21.651558Z"
        },
        "trusted": true,
        "id": "0rhmtdXPZpXz"
      },
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ImageAudioDataset(Dataset):\n",
        "    def __init__(self, root_dir, files, audio, labels=None, img_transform=None, audio_transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.files = files\n",
        "        self.audio = audio\n",
        "        self.labels = labels\n",
        "        self.img_transform = img_transform\n",
        "        self.audio_transform = audio_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(os.path.join(self.root_dir, self.files.iloc[idx]))\n",
        "        audio = self.audio[idx,:]\n",
        "        if self.img_transform is not None:\n",
        "            img = self.img_transform(img)\n",
        "        if self.audio_transform is not None:\n",
        "            audio = self.audio_transform(audio)\n",
        "        if self.labels is not None:\n",
        "            return img, audio, int(self.labels[idx])\n",
        "        else:\n",
        "            return img, audio\n",
        "\n",
        "import torchvision\n",
        "\n",
        "img_list_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((224,224)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# img_list_transform = None\n",
        "audio_transform = None\n",
        "\n",
        "img_dataset = ImageAudioDataset(root_dir=datadir,\n",
        "                               files=img_list,\n",
        "                                 audio=audio,\n",
        "                                 labels=labels,\n",
        "                              img_transform=img_list_transform,\n",
        "                                 audio_transform=audio_transform)\n",
        "## Taille du batch\n",
        "nsample = 100\n",
        "\n",
        "# img_dataset = ImageAudioDataset(root_dir=datadir,\n",
        "#                                files=img_list[:10*nsample],\n",
        "#                                  audio=audio[:10*nsample,:],\n",
        "#                                  labels=labels[:10*nsample],\n",
        "#                               img_transform=img_list_transform,\n",
        "#                                  audio_transform=audio_transform)\n",
        "\n",
        "# Shuffle = false pour echantillonner les données dans l'ordre\n",
        "img_loader = DataLoader(img_dataset, batch_size=nsample, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:24:21.655558Z",
          "iopub.execute_input": "2021-11-22T19:24:21.655914Z",
          "iopub.status.idle": "2021-11-22T19:24:29.453091Z",
          "shell.execute_reply.started": "2021-11-22T19:24:21.655875Z",
          "shell.execute_reply": "2021-11-22T19:24:29.452175Z"
        },
        "trusted": true,
        "id": "bYNhk2QzZpXz"
      },
      "source": [
        "import torchvision.models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "resnext = torchvision.models.resnext50_32x4d(pretrained=True, progress=True)\n",
        "\n",
        "# Si besoin de changer la derniere couche\n",
        "num_ftrs = resnext.fc.in_features\n",
        "resnext.fc = nn.Linear(num_ftrs, 9)\n",
        "\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    resnext = resnext.cuda()\n",
        "\n",
        "model = resnext\n",
        "\n",
        "\n",
        "#print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:24:29.454956Z",
          "iopub.execute_input": "2021-11-22T19:24:29.455574Z",
          "iopub.status.idle": "2021-11-22T19:24:29.470929Z",
          "shell.execute_reply.started": "2021-11-22T19:24:29.455535Z",
          "shell.execute_reply": "2021-11-22T19:24:29.470095Z"
        },
        "trusted": true,
        "id": "_ugRdybcZpXz"
      },
      "source": [
        "resnext.fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-11-22T19:24:29.472964Z",
          "iopub.execute_input": "2021-11-22T19:24:29.474529Z",
          "iopub.status.idle": "2021-11-22T19:25:47.988275Z",
          "shell.execute_reply.started": "2021-11-22T19:24:29.474498Z",
          "shell.execute_reply": "2021-11-22T19:25:47.986914Z"
        },
        "trusted": true,
        "id": "23SwKDYFZpX0"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "feat = []\n",
        "for i, data in enumerate(tqdm(img_loader)):   ## on itere sur les données \n",
        "    img, audio, targets = data\n",
        "    #print(targets)\n",
        "    if device.type == 'cuda':\n",
        "        img, audio, targets = img.cuda(), audio.cuda(), targets.cuda()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img)\n",
        "    if device.type == 'cuda':\n",
        "        feat.append(outputs.cpu().numpy().squeeze())\n",
        "    else:\n",
        "        feat.append(outputs.numpy().squeeze())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:25:47.989994Z",
          "iopub.execute_input": "2021-11-22T19:25:47.990391Z",
          "iopub.status.idle": "2021-11-22T19:25:48.014619Z",
          "shell.execute_reply.started": "2021-11-22T19:25:47.990350Z",
          "shell.execute_reply": "2021-11-22T19:25:48.013942Z"
        },
        "trusted": true,
        "id": "r2S4CNPjZpX0"
      },
      "source": [
        "torch.relu(torch.tensor(feat[-1][-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4fNhglBZpX0"
      },
      "source": [
        "# 1. Réseau de neuronnes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71c8eGmMZpX0"
      },
      "source": [
        "# 1.1 MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-9Oef5TZpX1"
      },
      "source": [
        "# 1.2 CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTqVIa5EZpX1"
      },
      "source": [
        "Thus, we turn to a neural network of type CNN to solve this task. CNNs are indeed widely used in image recognition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:25:48.016108Z",
          "iopub.execute_input": "2021-11-22T19:25:48.016590Z",
          "iopub.status.idle": "2021-11-22T19:25:48.021824Z",
          "shell.execute_reply.started": "2021-11-22T19:25:48.016551Z",
          "shell.execute_reply": "2021-11-22T19:25:48.020897Z"
        },
        "trusted": true,
        "id": "TNo41cl0ZpX1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiPNwA0FZpX2"
      },
      "source": [
        "**Creation of train and validation dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:25:48.023889Z",
          "iopub.execute_input": "2021-11-22T19:25:48.024228Z",
          "iopub.status.idle": "2021-11-22T19:25:48.033460Z",
          "shell.execute_reply.started": "2021-11-22T19:25:48.024189Z",
          "shell.execute_reply": "2021-11-22T19:25:48.032585Z"
        },
        "trusted": true,
        "id": "-KvKolJ_ZpX2"
      },
      "source": [
        "img_dataset_train,img_dataset_val = torch.utils.data.random_split(img_dataset, [10000, 3802])\n",
        "img_loader_train = DataLoader(img_dataset_train, batch_size=nsample, shuffle=False, num_workers=4, pin_memory=True)\n",
        "img_loader_val = DataLoader(img_dataset_val, batch_size=nsample, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:25:48.035336Z",
          "iopub.execute_input": "2021-11-22T19:25:48.035736Z",
          "iopub.status.idle": "2021-11-22T19:25:48.054423Z",
          "shell.execute_reply.started": "2021-11-22T19:25:48.035698Z",
          "shell.execute_reply": "2021-11-22T19:25:48.053455Z"
        },
        "trusted": true,
        "id": "r7VqEmrFZpX3"
      },
      "source": [
        "class MonReseauCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MonReseauCNN, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        \n",
        "        self.final = nn.Linear(50176,9)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.conv1(x)) ## l'image 3x224x224 devient 32x224x224\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2) ## puis 32x112x112\n",
        "        x = F.leaky_relu(self.conv2(x)) ## puis devient 64x112x112\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2) ## puis devient 64x56x56\n",
        "        x = F.leaky_relu(self.conv3(x)) ## pas de changement\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2) ## puis devient 64x28x28\n",
        "        x = F.leaky_relu(self.conv4(x)) ## pas de changement\n",
        "        \n",
        "        \n",
        "        x = x.view(-1,50176) ## 64x28x28 devient 50176\n",
        "        \n",
        "        x = self.final(x) \n",
        "        return x\n",
        "\n",
        "monreseauCNN = MonReseauCNN()\n",
        "monreseauCNN = monreseauCNN.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:25:48.055637Z",
          "iopub.execute_input": "2021-11-22T19:25:48.056041Z",
          "iopub.status.idle": "2021-11-22T19:25:48.060643Z",
          "shell.execute_reply.started": "2021-11-22T19:25:48.055988Z",
          "shell.execute_reply": "2021-11-22T19:25:48.059703Z"
        },
        "trusted": true,
        "id": "KyAQuh96ZpX3"
      },
      "source": [
        "optimizerCNN = optim.Adam(monreseauCNN.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "nbepoch = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:25:48.062244Z",
          "iopub.execute_input": "2021-11-22T19:25:48.062944Z",
          "iopub.status.idle": "2021-11-22T19:37:47.576500Z",
          "shell.execute_reply.started": "2021-11-22T19:25:48.062905Z",
          "shell.execute_reply": "2021-11-22T19:37:47.575187Z"
        },
        "trusted": true,
        "id": "QrrNMU-5ZpX4"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "for epoch in range(nbepoch):\n",
        "    monreseauCNN.train()\n",
        "    print(\"epoch\", epoch)\n",
        "    for inputs, data in enumerate(img_loader_train):   ## on itere sur les données \n",
        "        inputs,audio, targets = data\n",
        "        inputs, targets = inputs.cuda(),targets.cuda()\n",
        "\n",
        "        mespredictions = monreseauCNN(inputs)    ## on les fait rentrer dans le réseau\n",
        "        loss = criterion(mespredictions,targets)    ## on compare la sortie courante à la sortie voulue\n",
        "\n",
        "        optimizerCNN.zero_grad() ## supprime les gradients courants\n",
        "        loss.backward() ## le gradient \n",
        "        optimizerCNN.step() ## on actualise les poids pour que la sortie courante soit plus proche que la sortie voulue\n",
        "\n",
        "        if random.randint(0,90)==0:\n",
        "            print(\"\\tloss=\",loss) ## on affiche pour valider que ça diverge pas\n",
        "\n",
        "cm = np.zeros((9,9),dtype=int)\n",
        "monreseauCNN.eval()\n",
        "with torch.no_grad():  \n",
        "    for inputs, data in enumerate(img_loader_val):\n",
        "        inputs,audio, targets = data\n",
        "        inputs = inputs.cuda()\n",
        "        outputs = monreseauCNN(inputs)\n",
        "        _,pred = outputs.max(1)\n",
        "        cm += confusion_matrix(pred.cpu().numpy(),targets.cpu().numpy(),list(range(9)))\n",
        "\n",
        "# print(cm)\n",
        "# print(accuracy(cm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSDFLWIYZpX4"
      },
      "source": [
        "Result\n",
        "==\n",
        "Using a 4-layer CNN network, it is possible to obtain a score of 93.8% on the validation database with nsample = 100, nepochs = 15, learning rate = 0.0001.  \n",
        "Remark:  \n",
        "It is interesting to experiment with different types of CNN network(number of layer, number of channel, padding, stride ...). However, as the learning time is quite long, it is simpler to limit ourselves to light networks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:37:47.578107Z",
          "iopub.execute_input": "2021-11-22T19:37:47.578490Z",
          "iopub.status.idle": "2021-11-22T19:37:47.585619Z",
          "shell.execute_reply.started": "2021-11-22T19:37:47.578459Z",
          "shell.execute_reply": "2021-11-22T19:37:47.584591Z"
        },
        "trusted": true,
        "id": "SwrAFH4QZpX5"
      },
      "source": [
        "\n",
        "def accuracy(cm):\n",
        "    return np.sum(cm.diagonal())/np.sum(cm)\n",
        "print(accuracy(cm))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QK2BzHDZpX5"
      },
      "source": [
        "# 2.  Resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvMSOoKBZpX5"
      },
      "source": [
        "In this part, we will use a pre-trained network for location recognition. It is called Resnet. We will see in the following the detailed structure of this neural network.\n",
        "Moreover we are going to use fastai, a pytorch overlay which has many interests:  \n",
        "There are many functions that allow to evaluate the model.   \n",
        "The functions are well optimized and simple to implement.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06yj1qGXZpX6"
      },
      "source": [
        "* **Initialisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:37:47.587366Z",
          "iopub.execute_input": "2021-11-22T19:37:47.587960Z",
          "iopub.status.idle": "2021-11-22T19:39:43.682933Z",
          "shell.execute_reply.started": "2021-11-22T19:37:47.587923Z",
          "shell.execute_reply": "2021-11-22T19:39:43.682161Z"
        },
        "trusted": true,
        "id": "j9i6jiocZpX6"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *\n",
        "from fastai.vision.widgets import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:39:43.684303Z",
          "iopub.execute_input": "2021-11-22T19:39:43.684633Z",
          "iopub.status.idle": "2021-11-22T19:39:43.697081Z",
          "shell.execute_reply.started": "2021-11-22T19:39:43.684597Z",
          "shell.execute_reply": "2021-11-22T19:39:43.695745Z"
        },
        "trusted": true,
        "id": "oY25r2vjZpX6"
      },
      "source": [
        "#Retourne a partir d'un chemin de donnée, la liste des images de train\n",
        "def getImage(data):\n",
        "    L= []\n",
        "    for filename in os.listdir(data):\n",
        "        if filename.endswith(\".png\") and filename.startswith(\"train\"):\n",
        "            L.append((os.path.join(data, filename)))\n",
        "    return L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:39:43.698976Z",
          "iopub.execute_input": "2021-11-22T19:39:43.699658Z",
          "iopub.status.idle": "2021-11-22T19:39:43.705989Z",
          "shell.execute_reply.started": "2021-11-22T19:39:43.699616Z",
          "shell.execute_reply": "2021-11-22T19:39:43.705010Z"
        },
        "trusted": true,
        "id": "b9fUWq-vZpX7"
      },
      "source": [
        "#renvoie a partir d'une image son label\n",
        "def label_img(fname):\n",
        "    img = str(fname[-9:-4])\n",
        "    i = 0\n",
        "    while (img[i] == 0 & i<4):\n",
        "        i+=1\n",
        "    indice = int(img[i:])\n",
        "    return class_list[labels[indice]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTyrF70JZpX7"
      },
      "source": [
        "Creation of a DataBlock that will store the images with their labels, applying some transformations including a normalization, as well as a separation of the database into train and test.  \n",
        "The normalization of the data is very important because without it we get a lot of overfitting (+20% more error in general)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:39:43.707976Z",
          "iopub.execute_input": "2021-11-22T19:39:43.708572Z",
          "iopub.status.idle": "2021-11-22T19:39:43.720337Z",
          "shell.execute_reply.started": "2021-11-22T19:39:43.708493Z",
          "shell.execute_reply": "2021-11-22T19:39:43.719376Z"
        },
        "trusted": true,
        "id": "50Tgj1XYZpX7"
      },
      "source": [
        "scenes = DataBlock(\n",
        "    blocks = (ImageBlock, CategoryBlock),\n",
        "    get_items = getImage,\n",
        "    splitter = RandomSplitter(valid_pct=0.2,seed = 42),\n",
        "    get_y=label_img,\n",
        "batch_tfms=[*aug_transforms(size=(224,224)), Normalize.from_stats(*imagenet_stats)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:39:43.723452Z",
          "iopub.execute_input": "2021-11-22T19:39:43.723761Z",
          "iopub.status.idle": "2021-11-22T19:39:45.543790Z",
          "shell.execute_reply.started": "2021-11-22T19:39:43.723734Z",
          "shell.execute_reply": "2021-11-22T19:39:45.542807Z"
        },
        "trusted": true,
        "id": "TiI8U9d6ZpX7"
      },
      "source": [
        "dls = scenes.dataloaders(datadir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "536qkJBxZpX7"
      },
      "source": [
        "One of the advantages of fastai is that it has many functions to display the data like show_batch which allows to display the images of a batch with their label "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:39:45.545690Z",
          "iopub.execute_input": "2021-11-22T19:39:45.546095Z",
          "iopub.status.idle": "2021-11-22T19:39:47.419206Z",
          "shell.execute_reply.started": "2021-11-22T19:39:45.546044Z",
          "shell.execute_reply": "2021-11-22T19:39:47.418105Z"
        },
        "trusted": true,
        "id": "gfb43DiyZpX7"
      },
      "source": [
        "dls.valid.show_batch(max_n=10,nrows=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytknFNiHZpX8"
      },
      "source": [
        "* **Apprentissage**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxxrZPObZpX8"
      },
      "source": [
        "Apprentissage de resnet50 sur 4 epochs avec un learning rate de 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:39:47.420348Z",
          "iopub.execute_input": "2021-11-22T19:39:47.420708Z",
          "iopub.status.idle": "2021-11-22T19:47:29.090361Z",
          "shell.execute_reply.started": "2021-11-22T19:39:47.420673Z",
          "shell.execute_reply": "2021-11-22T19:47:29.089406Z"
        },
        "trusted": true,
        "id": "9q572LnkZpX8"
      },
      "source": [
        "learn = cnn_learner(dls,resnet50,metrics=error_rate,lr=0.001)\n",
        "learn.fine_tune(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvEdcDatZpX8"
      },
      "source": [
        "**Exemple de résultats**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:47:29.094501Z",
          "iopub.execute_input": "2021-11-22T19:47:29.096541Z",
          "iopub.status.idle": "2021-11-22T19:47:30.291824Z",
          "shell.execute_reply.started": "2021-11-22T19:47:29.096499Z",
          "shell.execute_reply": "2021-11-22T19:47:30.290983Z"
        },
        "trusted": true,
        "id": "93IuUqD1ZpX8"
      },
      "source": [
        "learn.show_results()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjo-8MkcZpX8"
      },
      "source": [
        "**Matrice de confusion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:47:30.293139Z",
          "iopub.execute_input": "2021-11-22T19:47:30.293692Z",
          "iopub.status.idle": "2021-11-22T19:47:46.597990Z",
          "shell.execute_reply.started": "2021-11-22T19:47:30.293652Z",
          "shell.execute_reply": "2021-11-22T19:47:46.597046Z"
        },
        "trusted": true,
        "id": "BhfOwhM8ZpX9"
      },
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHYRSL2kZpX9"
      },
      "source": [
        "**Affichage des prédictions les moins fiables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:47:46.599651Z",
          "iopub.execute_input": "2021-11-22T19:47:46.599997Z",
          "iopub.status.idle": "2021-11-22T19:47:47.030435Z",
          "shell.execute_reply.started": "2021-11-22T19:47:46.599967Z",
          "shell.execute_reply": "2021-11-22T19:47:47.029520Z"
        },
        "trusted": true,
        "id": "fbx9og0dZpX9"
      },
      "source": [
        "interp.plot_top_losses(5,nrows=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJgeO6rtZpX9"
      },
      "source": [
        "**Sauvegarde du modèle pour ne pas avoir à le recalculer à chaque fois.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:47:47.031723Z",
          "iopub.execute_input": "2021-11-22T19:47:47.032254Z",
          "iopub.status.idle": "2021-11-22T19:47:47.650671Z",
          "shell.execute_reply.started": "2021-11-22T19:47:47.032215Z",
          "shell.execute_reply": "2021-11-22T19:47:47.649483Z"
        },
        "trusted": true,
        "id": "9v8AHnsUZpX9"
      },
      "source": [
        "learn.save(\"fastaiCNN_Error_001\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:47:47.652397Z",
          "iopub.execute_input": "2021-11-22T19:47:47.652772Z",
          "iopub.status.idle": "2021-11-22T19:47:47.928435Z",
          "shell.execute_reply.started": "2021-11-22T19:47:47.652733Z",
          "shell.execute_reply": "2021-11-22T19:47:47.927591Z"
        },
        "trusted": true,
        "id": "8C39teDcZpX9"
      },
      "source": [
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkaVt09WZpX-"
      },
      "source": [
        "Result\n",
        "==\n",
        "Finally, the model takes less than 2min to be trained. This is longer than the methods used in the first part but it is still very convenient for the results obtained. Indeed the model obtained is very good, with a loss of 0.007 in training as in test, so no overfitting or underfitting.  \n",
        "However, we have to pay attention to the parameters before launching the model (like the learning rate, the number of epochs or the architecture used, here resnet50).  \n",
        "\n",
        "\n",
        "Finally, we have to be careful with the input data, there are 2 types of errors: \n",
        "* at the image level (blur, bad quality), even for a human, it is impossible to guess the represented scene  \n",
        "* at the level of the labels: an apron can be worn by a salesman as well as by a waiter. (ambiguous scene)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixZpLem8ZpX-"
      },
      "source": [
        "Avant d'utiliser le modèle sur la compétition, nous allons rapidement analyser la constitution du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:47:47.930204Z",
          "iopub.execute_input": "2021-11-22T19:47:47.930582Z",
          "iopub.status.idle": "2021-11-22T19:47:47.940709Z",
          "shell.execute_reply.started": "2021-11-22T19:47:47.930528Z",
          "shell.execute_reply": "2021-11-22T19:47:47.939734Z"
        },
        "trusted": true,
        "id": "hJAvbDf7ZpX-"
      },
      "source": [
        "learn.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtUCh6i0ZpX-"
      },
      "source": [
        "Thus the model used is like the model created by hand in the CNN part in that it uses Conv2d and ReLU. In addition to that, BatchNorm2d is used: the data in the batches are normalized in order to speed up the learning process.  \n",
        "At the end, the model uses a dropout with a probability of 0.5. This dropout is supposed to improve the regularization of the model.  \n",
        "Finally, there is a linear transformation that allows us to obtain the probabilities for each of our 9 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOnYEc0OZpX-"
      },
      "source": [
        "# Application sur la compétition Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHQ8poNJZpX-"
      },
      "source": [
        "* **Chargement du modèle et prédictions des données tests**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:47:47.942129Z",
          "iopub.execute_input": "2021-11-22T19:47:47.942664Z",
          "iopub.status.idle": "2021-11-22T19:47:48.973622Z",
          "shell.execute_reply.started": "2021-11-22T19:47:47.942623Z",
          "shell.execute_reply": "2021-11-22T19:47:48.972664Z"
        },
        "trusted": true,
        "id": "eqZIyAqPZpX_"
      },
      "source": [
        "learn = cnn_learner(dls,resnet50,metrics=error_rate,lr=0.001)\n",
        "learn.load(\"fastaiCNN_Error_001\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:47:48.975040Z",
          "iopub.execute_input": "2021-11-22T19:47:48.975401Z",
          "iopub.status.idle": "2021-11-22T19:47:49.183931Z",
          "shell.execute_reply.started": "2021-11-22T19:47:48.975361Z",
          "shell.execute_reply": "2021-11-22T19:47:49.183113Z"
        },
        "trusted": true,
        "id": "jnH2zm20ZpX_"
      },
      "source": [
        "datadir = '/kaggle/input/multimodal-classification-2021-mi203/data'\n",
        "#datadir = 'data'\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "\n",
        "data_df = pd.read_csv(os.path.join(datadir,'data_test_novt.csv'), delimiter=',', nrows = None)\n",
        "data_test = np.array(data_df)\n",
        "\n",
        "# labels_test = data[:,-1].astype('int32')\n",
        "\n",
        "# audio_test = data[:, 1:-1].astype('float32')\n",
        "\n",
        "img_list_test = data_df['IMAGE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:47:49.185548Z",
          "iopub.execute_input": "2021-11-22T19:47:49.185899Z",
          "iopub.status.idle": "2021-11-22T19:47:49.193135Z",
          "shell.execute_reply.started": "2021-11-22T19:47:49.185864Z",
          "shell.execute_reply": "2021-11-22T19:47:49.191051Z"
        },
        "trusted": true,
        "id": "7oymEpBAZpX_"
      },
      "source": [
        "#renvoie un array des testimg\n",
        "def testImg(img_test):\n",
        "    L = []\n",
        "    for img in img_test:\n",
        "        L.append(np.asarray(Image.open(os.path.join(datadir, str(img)))))\n",
        "    return np.asarray(L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T19:47:49.200781Z",
          "iopub.execute_input": "2021-11-22T19:47:49.201050Z",
          "iopub.status.idle": "2021-11-22T19:48:20.903651Z",
          "shell.execute_reply.started": "2021-11-22T19:47:49.201003Z",
          "shell.execute_reply": "2021-11-22T19:48:20.902650Z"
        },
        "trusted": true,
        "id": "FJqyp1nPZpX_"
      },
      "source": [
        "test_img = testImg(img_list_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:22.919148Z",
          "iopub.execute_input": "2021-11-22T20:07:22.919507Z",
          "iopub.status.idle": "2021-11-22T20:07:22.935719Z",
          "shell.execute_reply.started": "2021-11-22T20:07:22.919470Z",
          "shell.execute_reply": "2021-11-22T20:07:22.931504Z"
        },
        "trusted": true,
        "id": "IHim9swZZpYC"
      },
      "source": [
        "#renvoie une liste des prédictions\n",
        "def learner_results(test_img):\n",
        "    L = []\n",
        "    for img in test_img:\n",
        "        pred = learn.predict(img)\n",
        "        L.append([pred[0],pred[2][pred[1]]])#on ajoute le label ainsi que la \"confiance\" du modèle\n",
        "    return L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:22.941043Z",
          "iopub.execute_input": "2021-11-22T20:07:22.941549Z",
          "iopub.status.idle": "2021-11-22T20:07:22.951712Z",
          "shell.execute_reply.started": "2021-11-22T20:07:22.941515Z",
          "shell.execute_reply": "2021-11-22T20:07:22.950549Z"
        },
        "trusted": true,
        "id": "7NGGMWuIZpYC"
      },
      "source": [
        "#renvoie la liste des labels\n",
        "def learner_labels(L):\n",
        "    y_pred = []\n",
        "    for i in range(len(L)):\n",
        "        if (i%2 ==0):\n",
        "            y_pred.append(L[i])\n",
        "    return y_pred\n",
        "\n",
        "#renvoie la liste des \"confiances\"\n",
        "def learner_confiance(L):\n",
        "    conf = []\n",
        "    for i in range(len(L)):\n",
        "        if (i%2 == 1):\n",
        "            conf.append(L[i])\n",
        "    return conf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:22.954156Z",
          "iopub.execute_input": "2021-11-22T20:07:22.956151Z",
          "iopub.status.idle": "2021-11-22T20:07:22.965637Z",
          "shell.execute_reply.started": "2021-11-22T20:07:22.956110Z",
          "shell.execute_reply": "2021-11-22T20:07:22.964635Z"
        },
        "trusted": true,
        "id": "0o5CyKl1ZpYD"
      },
      "source": [
        "#renvoie les indices correspondants aux labels \n",
        "def learner_submission(L):\n",
        "    class_dict = { class_list[i] : i for i in range(len(class_list))}    \n",
        "    res = []\n",
        "    for i in L:\n",
        "        res.append(class_dict[i])\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:22.967192Z",
          "iopub.execute_input": "2021-11-22T20:07:22.968918Z",
          "iopub.status.idle": "2021-11-22T20:07:22.997044Z",
          "shell.execute_reply.started": "2021-11-22T20:07:22.968881Z",
          "shell.execute_reply": "2021-11-22T20:07:22.994994Z"
        },
        "trusted": true,
        "id": "LrApF8xTZpYD"
      },
      "source": [
        "y_pred = learner_labels(L)\n",
        "y_confidence = learner_confiance(L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:23.002496Z",
          "iopub.execute_input": "2021-11-22T20:07:23.006187Z",
          "iopub.status.idle": "2021-11-22T20:07:23.013650Z",
          "shell.execute_reply.started": "2021-11-22T20:07:23.006141Z",
          "shell.execute_reply": "2021-11-22T20:07:23.011692Z"
        },
        "trusted": true,
        "id": "uPxNIlfmZpYD"
      },
      "source": [
        "res = learner_submission(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NeyyspIZpYD"
      },
      "source": [
        "Kaggle Result\n",
        "==\n",
        "With this model we get a score of 99.5% on the Kaggle competition. \n",
        "3450 * (1-0.99594) = 14, there are about 14 misclassified images.  \n",
        "However, when analyzing the test images, we observe the same types of errors as on the train images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-dk2yV4ZpYD"
      },
      "source": [
        "For example, we can select the images whose model is the least certain. By displaying them, we observe that they are very ambiguous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:23.020318Z",
          "iopub.execute_input": "2021-11-22T20:07:23.020820Z",
          "iopub.status.idle": "2021-11-22T20:07:23.266797Z",
          "shell.execute_reply.started": "2021-11-22T20:07:23.020780Z",
          "shell.execute_reply": "2021-11-22T20:07:23.265955Z"
        },
        "trusted": true,
        "id": "eK6QPBL7ZpYE"
      },
      "source": [
        "print(y_confidence.index(min(y_confidence)))\n",
        "img = Image.open(os.path.join(datadir, 'testimg_03303.png'))\n",
        "plt.imshow(np.asarray(img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:23.268072Z",
          "iopub.execute_input": "2021-11-22T20:07:23.268577Z",
          "iopub.status.idle": "2021-11-22T20:07:23.274273Z",
          "shell.execute_reply.started": "2021-11-22T20:07:23.268537Z",
          "shell.execute_reply": "2021-11-22T20:07:23.273119Z"
        },
        "trusted": true,
        "id": "I0bEcT2oZpYE"
      },
      "source": [
        "y_pred[3303]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zPi3t6aZpYE"
      },
      "source": [
        "This is the image of which the model is the least certain. He classifies it as \"GROCERY-STORE\". We can understand this choice because we have the impression of being located indoors and the blue element seems to be a cadis. However it is very likely that the dataset is labeled as \"CLASSROOM\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:23.275584Z",
          "iopub.execute_input": "2021-11-22T20:07:23.276247Z",
          "iopub.status.idle": "2021-11-22T20:07:23.320928Z",
          "shell.execute_reply.started": "2021-11-22T20:07:23.276207Z",
          "shell.execute_reply": "2021-11-22T20:07:23.320118Z"
        },
        "trusted": true,
        "id": "LJuSduOeZpYF"
      },
      "source": [
        "predictions_copy = y_confidence.copy()\n",
        "predictions_copy.sort() #classement des prédictions dans l'ordre croissant\n",
        "predictions_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:23.322109Z",
          "iopub.execute_input": "2021-11-22T20:07:23.322592Z",
          "iopub.status.idle": "2021-11-22T20:07:23.348962Z",
          "shell.execute_reply.started": "2021-11-22T20:07:23.322555Z",
          "shell.execute_reply": "2021-11-22T20:07:23.347794Z"
        },
        "trusted": true,
        "id": "cr_QJznZZpYF"
      },
      "source": [
        "print(y_confidence.index('tensor(0.7618)')) #correspond à l'indice de l'image dont le modèle a une proba de 0.7618\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:23.350066Z",
          "iopub.status.idle": "2021-11-22T20:07:23.350807Z"
        },
        "trusted": true,
        "id": "cd62fm3kZpYF"
      },
      "source": [
        "y_pred[64] #correspond au label prédit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxBnneeIZpYH"
      },
      "source": [
        "# Images with the lowest confidence in our model:\n",
        "testimg_00651.png => Oversaturated image, predicts as \"RESTAURANT\" but doesn't look like anything in reality  \n",
        "testimg_01910.png => Looks like a casino     \n",
        "testimg_02004.png => Predicted as \"GROCERY-STORE\" but looks more like a restaurant kitchen  \n",
        "testimg_02813.png => Predicted as \"GROCERY-STORE\". However the image is blurred and it is impossible to discern anything  \n",
        "testimg_02817.png => Predicted as \"RESTAURANT\". However the scene does not seem to be classifiable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:08:33.668153Z",
          "iopub.execute_input": "2021-11-22T20:08:33.668597Z",
          "iopub.status.idle": "2021-11-22T20:08:33.674186Z",
          "shell.execute_reply.started": "2021-11-22T20:08:33.668555Z",
          "shell.execute_reply": "2021-11-22T20:08:33.673095Z"
        },
        "trusted": true,
        "id": "asuHv1t9ZpYI"
      },
      "source": [
        "#affiche l'image n°x\n",
        "def show_image(x):\n",
        "    img = Image.open(os.path.join(datadir, 'testimg_'+x+'.png'))\n",
        "    plt.imshow(np.asarray(img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:08:35.743740Z",
          "iopub.execute_input": "2021-11-22T20:08:35.744090Z",
          "iopub.status.idle": "2021-11-22T20:08:35.884483Z",
          "shell.execute_reply.started": "2021-11-22T20:08:35.744056Z",
          "shell.execute_reply": "2021-11-22T20:08:35.883479Z"
        },
        "trusted": true,
        "id": "Q-ukzjVpZpYJ"
      },
      "source": [
        "show_image('00651')\n",
        "# show_image('01910')\n",
        "# show_image('02004')\n",
        "# show_image('02813')\n",
        "# show_image('02817')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo5unUjNZpYJ"
      },
      "source": [
        "# III. Multimodal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EccuKs8fZpYJ"
      },
      "source": [
        "In view of the results obtained in the last section, it seems unnecessary to try to make the model more complex to obtain better results.\n",
        "However, it may be interesting to examine some approaches that allow to solve multimodal problems.  \n",
        "For example, there is an approach in the literature that consists in using 3 neural networks:\n",
        "The first one that takes as input the images, the second one takes as input the MFCC coefficients. Finally the last one takes as input the results of these 2 first neural networks and returns the prediction.  \n",
        "Indeed, in the first part, nothing prevented us from using a neural network. However, the performance of CNNs on image recognition has encouraged us to reserve this method for the second part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AIcmV2bZpYK"
      },
      "source": [
        "However, there is an intuitive and fairly simple multimodal method that we will try to implement.  \n",
        "It consists in examining the elements for which the model is the least certain using the tools of the first part. Indeed, if the images do not clearly distinguish the location, perhaps the audio files do. It is unlikely that both the image and the sound are unusable for the same element."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:08:41.826956Z",
          "iopub.execute_input": "2021-11-22T20:08:41.827339Z",
          "iopub.status.idle": "2021-11-22T20:08:41.833351Z",
          "shell.execute_reply.started": "2021-11-22T20:08:41.827306Z",
          "shell.execute_reply": "2021-11-22T20:08:41.832057Z"
        },
        "trusted": true,
        "id": "87kTYFwCZpYK"
      },
      "source": [
        "#Retourne une liste contenant les éléments dont le modèle est le moins sûr\n",
        "def least_confident(pred):\n",
        "    predictions_copy = pred.copy()\n",
        "    predictions_copy.sort()\n",
        "    return predictions_copy[:25]#nous choisissons les 25 éléments avec les probas les plus faibles. Ce choix est arbitraire\n",
        "\n",
        "#Modifie la liste res des prédictions avec les nouvelles prédictions via le SVM de la partie I.\n",
        "def new_predictions(probas):\n",
        "    y_pred_SVM = svc.predict(scaler.transform(audio_test)) #Prédit les audio_test en utilisant un SVM de la partie I.\n",
        "    for x in probas:\n",
        "        index = y_confidence.index(x)\n",
        "        res[index] = y_pred_SVM[index]#modifie le résultat final\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:08:44.240507Z",
          "iopub.execute_input": "2021-11-22T20:08:44.240847Z",
          "iopub.status.idle": "2021-11-22T20:08:46.606662Z",
          "shell.execute_reply.started": "2021-11-22T20:08:44.240814Z",
          "shell.execute_reply": "2021-11-22T20:08:46.605795Z"
        },
        "trusted": true,
        "id": "wEzlPMUgZpYL"
      },
      "source": [
        "new_predictions(predictions_copy[:28])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abebnHJIZpYL"
      },
      "source": [
        "Result \n",
        "==\n",
        "The intuitive idea paid off. We now get a score of 0.99942 instead of 0.99594. This means that out of 3450 items to classify, our model makes 2 errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV00oGx0ZpYL"
      },
      "source": [
        "# Creating the rendering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-22T20:07:23.359408Z",
          "iopub.status.idle": "2021-11-22T20:07:23.360148Z"
        },
        "trusted": true,
        "id": "VaGGSX-rZpYL"
      },
      "source": [
        "#====================================================================\n",
        "# Création du ficher de soumission\n",
        "\n",
        "submission = pd.DataFrame({'CLASS':res})\n",
        "submission=submission.reset_index()\n",
        "submission = submission.rename(columns={'index': 'Id'})\n",
        "\n",
        "#======================================================================\n",
        "# Sauvegarde du fichier\n",
        "submission.to_csv('ThomasNigoghossian3.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5FwOCctZpYL"
      },
      "source": [
        "# In depth \n",
        "Articles on multimodal prediction\n",
        "\n",
        "https://www.youtube.com/watch?v=VIq5r7mCAyw&list=PLTLz0-WCKX616TjsrgPr2wFzKF54y-ZKc&ab_channel=CMU11-777course\n",
        "\n",
        " coefficients MFCC, cf https://github.com/devinvenable/mfcc-audio-experiment/blob/master/MFCC%20transforms.ipynb\n"
      ]
    }
  ]
}